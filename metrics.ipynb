{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# replace this with a Spark history log of your own or parameterize with Papermill!\n",
    "\n",
    "metrics_file = \"metrics/application_1601392010735_0030\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "import json\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = spark.read.json(metrics_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_id, app_name = metrics.select(\"App ID\", \"App Name\").dropna().collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_and_dictify(df):\n",
    "    return [json.loads(row[0]) for row in df.selectExpr(\"to_json(*)\").collect()]\n",
    "\n",
    "def executor_info(df):\n",
    "    info = df.select(\"Executor Info\").dropna()\n",
    "    return collect_and_dictify(info)\n",
    "\n",
    "def plan_dicts(df):\n",
    "    return collect_and_dictify(df.select(\"sparkPlanInfo\").dropna())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "MetricNode = namedtuple(\"MetricNode\", \"plan_node accumulatorId metricType name\")\n",
    "PlanInfoNode = namedtuple(\"PlanInfoNode\", \"plan_node parent nodeName simpleString\")\n",
    "\n",
    "def nextid():\n",
    "    i = 0\n",
    "    while True:\n",
    "        yield i\n",
    "        i = i + 1\n",
    "    \n",
    "node_ctr = nextid()\n",
    "\n",
    "def plan_dicts(df):\n",
    "    return collect_and_dictify(df.select(\"sparkPlanInfo\").dropna())\n",
    "\n",
    "def flatplan(dicts, parent=-1, plan_nodes=None, metric_nodes=None):\n",
    "    if plan_nodes is None:\n",
    "        plan_nodes = list()\n",
    "        \n",
    "    if metric_nodes is None:\n",
    "        metric_nodes = list()\n",
    "    \n",
    "    for pd in dicts:\n",
    "        pid = next(node_ctr)\n",
    "        for m in pd['metrics']:\n",
    "            metric_nodes.append(MetricNode(pid, m['accumulatorId'], m['metricType'], m['name']))\n",
    "        \n",
    "        plan_nodes.append(PlanInfoNode(pid, parent, pd['nodeName'], pd['simpleString']))\n",
    "        \n",
    "        flatplan(pd['children'], pid, plan_nodes, metric_nodes)\n",
    "    \n",
    "    return(plan_nodes, metric_nodes)\n",
    "\n",
    "def plan_dfs(df):\n",
    "    pn, mn = flatplan(plan_dicts(metrics))\n",
    "    \n",
    "    pndf = spark.createDataFrame(data=pn)\n",
    "    mndf = spark.createDataFrame(data=mn)\n",
    "    \n",
    "    return (pndf, mndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_nodes, accumulable_nodes = plan_dfs(metrics)\n",
    "pn, mn = flatplan(plan_dicts(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tasks_to_stages(df):\n",
    "    return df.where(F.col('Event') == 'SparkListenerTaskStart').select(F.col(\"Task Info.Task ID\").alias('Task ID'), 'Stage ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulables(df, noun='Task', extra_cols=[]):\n",
    "    mcol = '%s Info' % noun\n",
    "    idcol = '%s ID' % noun\n",
    "    \n",
    "    acc_cols = [F.col('Accumulable.%s' % s).alias('Metric %s' % s) for s in ['ID', 'Name', 'Value']]\n",
    "    obs = df.select(mcol, *extra_cols).select('%s.*' % mcol, *extra_cols)\n",
    "    cols = [F.col(elt) for elt in sorted(set(obs.columns) - set([idcol, 'Accumulables']))]\n",
    "    \n",
    "    return obs.select(\n",
    "        idcol, \n",
    "        F.explode('Accumulables').alias('Accumulable'), \n",
    "        *(cols)\n",
    "    ).select(\n",
    "        idcol, \n",
    "        *(cols + acc_cols)\n",
    "    ).withColumnRenamed(\"Metric ID\", \"accumulatorId\").withColumn(\"Metric Value\", F.col(\"Metric Value\").cast(\"float\"))\n",
    "\n",
    "def tidy_metrics(df, noun='Task', event=None, interesting_metrics=None, extra_cols=[]):\n",
    "    mcol = '%s Info' % noun\n",
    "    idcol = '%s ID' % noun\n",
    "    \n",
    "    if event is not None:\n",
    "        event_selector = (F.col('Event') == event)\n",
    "    else:\n",
    "        event_selector = F.lit(True)\n",
    "    \n",
    "    filtered = df.where(event_selector)\n",
    "    \n",
    "    metric_cols = \"\"\n",
    "    \n",
    "    return accumulables(filtered, noun, extra_cols)\n",
    "\n",
    "def tidy_tasks(df, event='SparkListenerTaskEnd', interesting_metrics=None):\n",
    "    return tidy_metrics(df, 'Task', event=event, interesting_metrics=(interesting_metrics or F.lit(True)), extra_cols=[\"Stage ID\"])\n",
    "\n",
    "def tidy_stages(df, event='SparkListenerStageCompleted', interesting_metrics=None):\n",
    "    return tidy_metrics(df, 'Stage', event=event, interesting_metrics=F.lit(True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetricMeta = namedtuple('MetricMeta', 'MetricName kind unit')\n",
    "\n",
    "metric_metas = [\n",
    "    MetricMeta('GPU decode time', 'time', 'ms'),\n",
    "    MetricMeta('GPU time', 'time', 'ms'),\n",
    "    MetricMeta('avg hash probe bucket list iters', 'count', 'iterations'),\n",
    "    MetricMeta('buffer time', 'time', 'ms'),\n",
    "    MetricMeta('build side size', 'size', 'bytes'),\n",
    "    MetricMeta('build time', 'time', 'ms'),\n",
    "    MetricMeta('collect batch time', 'time', 'ms'),\n",
    "    MetricMeta('concat batch time', 'time', 'ms'),\n",
    "    MetricMeta('data size', 'size', 'bytes'),\n",
    "    MetricMeta('duration', 'time', 'ms'),\n",
    "    MetricMeta('fetch wait time', 'time', 'ms'),\n",
    "    MetricMeta('internal.metrics.diskBytesSpilled', 'size', 'bytes'),\n",
    "    MetricMeta('internal.metrics.executorCpuTime', 'time', 'ns'),\n",
    "    MetricMeta('internal.metrics.executorDeserializeCpuTime', 'time', 'ns'),\n",
    "    MetricMeta('internal.metrics.executorDeserializeTime', 'time', 'ms'),\n",
    "    MetricMeta('internal.metrics.executorRunTime', 'time', 'ms'),\n",
    "    MetricMeta('internal.metrics.input.bytesRead', 'size', 'bytes'),\n",
    "    MetricMeta('internal.metrics.input.recordsRead', 'count', 'records'),\n",
    "    MetricMeta('internal.metrics.jvmGCTime', 'time', 'ms'),\n",
    "    MetricMeta('internal.metrics.memoryBytesSpilled', 'size', 'bytes'),\n",
    "    MetricMeta('internal.metrics.output.bytesWritten', 'size', 'bytes'),\n",
    "    MetricMeta('internal.metrics.output.recordsWritten', 'count', 'records'),\n",
    "    MetricMeta('internal.metrics.peakExecutionMemory', 'size', 'bytes'),\n",
    "    MetricMeta('internal.metrics.resultSerializationTime', 'time', 'ms'),\n",
    "    MetricMeta('internal.metrics.resultSize', 'size', 'bytes'),\n",
    "    MetricMeta('internal.metrics.shuffle.read.fetchWaitTime', 'time', 'ms'),\n",
    "    MetricMeta('internal.metrics.shuffle.read.localBlocksFetched', 'count', 'blocks'),\n",
    "    MetricMeta('internal.metrics.shuffle.read.localBytesRead', 'size', 'bytes'),\n",
    "    MetricMeta('internal.metrics.shuffle.read.recordsRead', 'count', 'records'),\n",
    "    MetricMeta('internal.metrics.shuffle.read.remoteBlocksFetched', 'count', 'blocks'),\n",
    "    MetricMeta('internal.metrics.shuffle.read.remoteBytesRead', 'size', 'bytes'),\n",
    "    MetricMeta('internal.metrics.shuffle.read.remoteBytesReadToDisk', 'size', 'bytes'),\n",
    "    MetricMeta('internal.metrics.shuffle.write.bytesWritten', 'size', 'bytes'),\n",
    "    MetricMeta('internal.metrics.shuffle.write.recordsWritten', 'count', 'records'),\n",
    "    MetricMeta('internal.metrics.shuffle.write.writeTime', 'time', 'ms'),\n",
    "    MetricMeta('join output rows', 'count', 'rows'),\n",
    "    MetricMeta('join time', 'time', 'ms'),\n",
    "    MetricMeta('local blocks read', 'count', 'blocks'),\n",
    "    MetricMeta('local bytes read', 'size', 'bytes'),\n",
    "    MetricMeta('number of input columnar batches', 'count', 'batches'),\n",
    "    MetricMeta('number of input rows', 'count', 'rows'),\n",
    "    MetricMeta('number of output columnar batches', 'count', 'batches'),\n",
    "    MetricMeta('number of output rows', 'count', 'rows'),\n",
    "    MetricMeta('peak device memory', 'size', 'bytes'),\n",
    "    MetricMeta('peak memory', 'size', 'bytes'),\n",
    "    MetricMeta('records read', 'count', 'records'),\n",
    "    MetricMeta('remote blocks read', 'count', 'blocks'),\n",
    "    MetricMeta('remote bytes read', 'size', 'bytes'),\n",
    "    MetricMeta('scan time', 'time', 'ms'),\n",
    "    MetricMeta('shuffle bytes written', 'size', 'bytes'),\n",
    "    MetricMeta('shuffle records written', 'count', 'records'),\n",
    "    MetricMeta('shuffle write time', 'time', 'ms'),\n",
    "    MetricMeta('spill size', 'size', 'bytes'),\n",
    "    MetricMeta('sort time', 'time', 'ms'),\n",
    "    MetricMeta('time in aggregation build', 'time', 'ms'),\n",
    "    MetricMeta('time in batch concat', 'time', 'ms'),\n",
    "    MetricMeta('time in compute agg', 'time', 'ms'),\n",
    "    MetricMeta('total time', 'time', 'ns'),\n",
    "    MetricMeta('write time', 'time', 'ms')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_meta = spark.createDataFrame(data=metric_metas)\n",
    "task_metrics = tidy_tasks(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_metrics.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_to_plans = task_metrics.join(accumulable_nodes, \"accumulatorId\").join(plan_nodes, \"plan_node\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_to_plans.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "alt.data_transformers.enable('json')\n",
    "\n",
    "def stage_and_task_charts(task_metrics_df, noun=\"Time\"):\n",
    "    \n",
    "    selection = alt.selection_multi(name=\"SelectorName\", fields=['Stage ID'])\n",
    "    stage_metrics_df = task_metrics_df.groupby(['Stage ID', 'Metric Name']).sum()\n",
    "    \n",
    "    stages = alt.Chart(\n",
    "        stage_metrics_df.reset_index()\n",
    "    ).mark_bar().encode(\n",
    "        x='Stage ID:N',\n",
    "        y=alt.Y('sum(Metric Value):Q', title=noun),\n",
    "        color='Metric Name:N',\n",
    "        tooltip=['Metric Name', 'Metric Value', 'Task ID']\n",
    "    ).add_selection(selection).interactive()\n",
    "    \n",
    "    tasks = alt.Chart(\n",
    "        task_metrics_df.reset_index()\n",
    "    ).mark_bar().encode(\n",
    "        x='Task ID:N',\n",
    "        y=alt.Y('sum(Metric Value):Q', title=noun),\n",
    "        color='Metric Name:N',\n",
    "        tooltip=['Metric Name', 'Metric Value', 'Task ID']\n",
    "    ).transform_filter(\n",
    "        selection\n",
    "    ).interactive()\n",
    "\n",
    "    return alt.vconcat(stages, tasks)\n",
    "\n",
    "def layered_stage_and_task_charts(task_layers, noun=\"Time\"):\n",
    "    \n",
    "    selection = alt.selection_multi(name=\"selector_SelectorName\", fields=['Stage ID'])\n",
    "    sdfs = [tdf.groupby(['Stage ID', 'Metric Name']).sum() for tdf in task_layers]\n",
    "    \n",
    "    stages = alt.layer(*[alt.Chart(\n",
    "        sdf.reset_index()\n",
    "    ).mark_bar().encode(\n",
    "        x='Stage ID:N',\n",
    "        y=alt.Y('sum(Metric Value):Q', title=noun),\n",
    "        color='Metric Name:N',\n",
    "        tooltip=['Metric Name', 'Metric Value', 'Task ID']\n",
    "    ) for sdf in sdfs]).add_selection(selection).interactive()\n",
    "    \n",
    "    tasks = alt.layer(*[alt.Chart(\n",
    "        tdf.reset_index()\n",
    "    ).mark_bar().encode(\n",
    "        x='Task ID:N',\n",
    "        y=alt.Y('sum(Metric Value):Q', title=noun),\n",
    "        color='Metric Name:N',\n",
    "        tooltip=['Metric Name', 'Metric Value', 'Task ID']\n",
    "    ).transform_filter(\n",
    "        selection\n",
    "    ) for tdf in task_layers]).interactive()\n",
    "\n",
    "    return alt.vconcat(stages, tasks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "task_metrics.select(\"Metric Name\").distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_byte_metrics = tidy_tasks(metrics).join(\n",
    "    metric_meta.withColumnRenamed(\"MetricName\", \"Metric Name\"), \n",
    "    \"Metric Name\", \n",
    "    how=\"outer\"\n",
    ").where(F.col(\"unit\") == \"bytes\").groupBy(\"Stage ID\", \"Task ID\", \"Metric Name\").sum(\"Metric Value\").withColumnRenamed(\"sum(Metric Value)\", \"Metric Value\").toPandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_shuffle_metrics = task_byte_metrics[task_byte_metrics['Metric Name'].str.contains('internal.metrics.shuffle')].sort_values('Task ID')\n",
    "shuffle_replacer = lambda match: \"Shuffle %s\" % match.group('metric')\n",
    "task_shuffle_metrics['Metric Name'] = task_shuffle_metrics['Metric Name'].str.replace(r'internal\\.metrics\\.shuffle\\.(?P<kind>read|write).(?P<metric>.*)$', shuffle_replacer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_and_task_charts(task_shuffle_metrics, \"bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executor time metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "task_metrics = tidy_tasks(metrics).join(\n",
    "    metric_meta.withColumnRenamed(\"MetricName\", \"Metric Name\"), \n",
    "    \"Metric Name\", \n",
    "    how=\"outer\"\n",
    ").withColumn(\"Metric Value\", F.col(\"Metric Value\").cast(\"float\"))\n",
    "\n",
    "task_ms_metrics = task_metrics.where(F.col(\"unit\") == \"ms\").groupBy(\"Stage ID\", \"Task ID\", \"Metric Name\").sum(\"Metric Value\").withColumnRenamed(\"sum(Metric Value)\", \"Metric Value\")\n",
    "task_ns_metrics = task_metrics.where(F.col(\"unit\") == \"ns\").groupBy(\"Stage ID\", \"Task ID\", \"Metric Name\").sum(\"Metric Value\").withColumnRenamed(\"sum(Metric Value)\", \"Metric Value\").withColumn(\"Metric Value\", F.col(\"Metric Value\").cast(\"float\") / 1000000)\n",
    "\n",
    "task_time_metrics = task_ms_metrics.union(task_ns_metrics).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "task_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_executor_metrics = task_time_metrics[~task_time_metrics['Metric Name'].str.contains('internal.metrics.shuffle.')].sort_values('Task ID')\n",
    "\n",
    "stage_and_task_charts(task_executor_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting wall-clock vs CPU time with layered charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cputime = task_time_metrics[task_time_metrics['Metric Name'].str.contains('executorCpuTime')]\n",
    "runtime = task_time_metrics[task_time_metrics['Metric Name'].str.contains('executorRunTime')]\n",
    "layered_stage_and_task_charts([runtime, cputime])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory and spill metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stage_and_task_charts(task_byte_metrics[task_byte_metrics['Metric Name'].str.contains('memory') | task_byte_metrics['Metric Name'].str.contains('size') | task_byte_metrics['Metric Name'].str.contains('pill')], \"bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_and_task_charts(task_byte_metrics, \"bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Configuration information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt(df, id_vars=None, value_vars=None, var_name='variable', value_name='value'):\n",
    "    if id_vars is None:\n",
    "        id_vars = []\n",
    "    \n",
    "    if value_vars is None:\n",
    "        value_vars = [c for c in df.columns if c not in id_vars]\n",
    "    \n",
    "    return df.withColumn(\n",
    "        \"value_tuple\",\n",
    "        F.explode(\n",
    "            F.array(\n",
    "                *[\n",
    "                    F.struct(\n",
    "                        F.lit(vv).alias(var_name), \n",
    "                        F.col(\"`%s`\" % vv).alias(value_name)\n",
    "                    ) \n",
    "                    for vv in value_vars\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    ).select(*(id_vars + [F.col(\"value_tuple\")[cn].alias(cn) for cn in [var_name, value_name]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meltmetrics(raw_df, event):\n",
    "    if event is not None:\n",
    "        if isinstance(event, list):\n",
    "            df = raw_df.where(F.col(\"Event\").isin(event))\n",
    "        else:\n",
    "            df = raw_df.where(F.col(\"Event\") == event)\n",
    "    else:\n",
    "        df = raw_df\n",
    "            \n",
    "    def helper(df, field):\n",
    "        return melt(df.select(field).dropna().select(\"%s.*\" % field))\n",
    "\n",
    "    return helper(df, \"Properties\").union(helper(df, \"System Properties\")).union(helper(df, \"Hadoop Properties\")).distinct()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meltmetrics(metrics, [\"SparkListenerEnvironmentUpdate\",\"SparkListenerJobStart\"]).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
